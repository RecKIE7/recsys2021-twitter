{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "dask-cudf",
   "display_name": "dask-cudf",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Baseline - Predict engagements by popular creator's tweet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "\n",
    "from utils.cuda_cluster import *\n",
    "from utils.dataset import read_data, factorize_small_cardinality, df_to_tfdataset\n",
    "from utils.evaluate import calculate_ctr, compute_rce, average_precision_score\n",
    "\n",
    "import core.config as conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33513' processes=1 threads=1, memory=33.47 GB>"
      ],
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:33513</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>1</li>\n  <li><b>Cores: </b>1</li>\n  <li><b>Memory: </b>33.47 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "source": [
    "## 1. Load data & preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of rows: 3033347\n"
     ]
    }
   ],
   "source": [
    "# data_path = conf.raw_data_path + '*' # for all dataset\n",
    "data_path = conf.raw_data_path + 'part-00175'\n",
    "ori_df = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['text_ tokens', 'hashtags', 'tweet_id', 'present_media',\n",
       "       'present_links', 'present_domains', 'tweet_type', 'language',\n",
       "       'tweet_timestamp', 'engaged_with_user_id',\n",
       "       'engaged_with_user_follower_count', 'engaged_with_user_following_count',\n",
       "       'engaged_with_user_is_verified', 'engaged_with_user_account_creation',\n",
       "       'enaging_user_id', 'enaging_user_follower_count',\n",
       "       'enaging_user_following_count', 'enaging_user_is_verified',\n",
       "       'enaging_user_account_creation', 'engagee_follows_engager',\n",
       "       'reply_timestamp', 'retweet_timestamp',\n",
       "       'retweet_with_comment_timestamp', 'like_timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ori_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ori_df[['enaging_user_id', 'tweet_id', 'language', 'engaged_with_user_follower_count', 'reply_timestamp', 'retweet_timestamp','retweet_with_comment_timestamp', 'like_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_reply'] = df['reply_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_retweet'] = df['retweet_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_comment'] = df['retweet_with_comment_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_like'] = df['like_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "\n",
    "df['positive_cnt'] = df[['is_like', 'is_retweet', 'is_reply', 'is_comment']].sum(axis=1).astype(np.uint8)\n",
    "\n",
    "df = df.drop('reply_timestamp', axis=1)\n",
    "df = df.drop('retweet_timestamp', axis=1)\n",
    "df = df.drop('retweet_with_comment_timestamp', axis=1)\n",
    "df = df.drop('like_timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, idx_to_tweet = factorize_small_cardinality(df, 'tweet_id')\n",
    "df, idx_to_language = factorize_small_cardinality(df, 'language') # how language encoding??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     enaging_user_id                          tweet_id  \\\n",
       "id                                                                       \n",
       "1   411C3FA9B6AB5CA95192D875CDC22823  C8F345CF8BC7A86E34572072ECFBBEC4   \n",
       "2   E764026AB0E38A5C2FF19921D73B6C18  C1E31636C343B780BA776E4B73147028   \n",
       "3   455134BAAD3EAC4093393EC233FBAEF9  B436C84E80C2430BA9DE41FDF04C73BF   \n",
       "4   92D70497B86CAFBA5C51E331084462AD  033FFA42C8AD502057AE96C8B4B812BE   \n",
       "5   DC1C8A9412B9E266A4C3D4CAF6DB06CB  84F2E902BA3CF3B34B8D056F6F78D488   \n",
       "\n",
       "                            language  engaged_with_user_follower_count  \\\n",
       "id                                                                       \n",
       "1   B8B04128918BBF54E2E178BFF1ABA833                              4753   \n",
       "2   9FCF19233EAD65EA6E32C2E6DC03A444                            110643   \n",
       "3   B0FA488F2911701DD8EC5B1EA5E322D8                              4480   \n",
       "4   1F73BB863A39DB62B4A55B7E558DB1E8                               461   \n",
       "5   E7F038DE3EAD397AEC9193686C911677                              1308   \n",
       "\n",
       "    is_reply  is_retweet  is_comment  is_like  positive_cnt  language_encode  \n",
       "id                                                                            \n",
       "1          0           0           0        1             1               48  \n",
       "2          0           0           0        0             0               43  \n",
       "3          1           0           0        0             1               46  \n",
       "4          0           0           0        1             1                5  \n",
       "5          0           0           0        0             0               61  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enaging_user_id</th>\n      <th>tweet_id</th>\n      <th>language</th>\n      <th>engaged_with_user_follower_count</th>\n      <th>is_reply</th>\n      <th>is_retweet</th>\n      <th>is_comment</th>\n      <th>is_like</th>\n      <th>positive_cnt</th>\n      <th>language_encode</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>411C3FA9B6AB5CA95192D875CDC22823</td>\n      <td>C8F345CF8BC7A86E34572072ECFBBEC4</td>\n      <td>B8B04128918BBF54E2E178BFF1ABA833</td>\n      <td>4753</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E764026AB0E38A5C2FF19921D73B6C18</td>\n      <td>C1E31636C343B780BA776E4B73147028</td>\n      <td>9FCF19233EAD65EA6E32C2E6DC03A444</td>\n      <td>110643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>455134BAAD3EAC4093393EC233FBAEF9</td>\n      <td>B436C84E80C2430BA9DE41FDF04C73BF</td>\n      <td>B0FA488F2911701DD8EC5B1EA5E322D8</td>\n      <td>4480</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92D70497B86CAFBA5C51E331084462AD</td>\n      <td>033FFA42C8AD502057AE96C8B4B812BE</td>\n      <td>1F73BB863A39DB62B4A55B7E558DB1E8</td>\n      <td>461</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DC1C8A9412B9E266A4C3D4CAF6DB06CB</td>\n      <td>84F2E902BA3CF3B34B8D056F6F78D488</td>\n      <td>E7F038DE3EAD397AEC9193686C911677</td>\n      <td>1308</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "### train, valid data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = {\n",
    "    'engaged_with_user_follower_count' : fc.numeric_column('engaged_with_user_follower_count', normalizer_fn=lambda x: (x - 3.0) / 4.2)\n",
    "}\n",
    "\n",
    "sparse = {\n",
    "    'language_encode' : fc.categorical_column_with_hash_bucket('language_encode', hash_bucket_size=66),\n",
    "}\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=(), dtype='float32') \\\n",
    "          for colname in real.keys()\n",
    "}\n",
    "inputs.update({\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=( ), dtype='string') \\\n",
    "          for colname in sparse.keys()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'engaged_with_user_follower_count': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'engaged_with_user_follower_count')>,\n",
       " 'language_encode': <KerasTensor: shape=(None,) dtype=string (created by layer 'language_encode')>}"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "source": [
    "## 3. Modeling (using wide model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = tf.keras.layers.DenseFeatures(real.values())(inputs)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(wide)\n",
    "model = tf.keras.Model(inputs, output)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1)\n",
    "model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error', #binary_crossentropy\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nengaged_with_user_follower_coun [(None,)]            0                                            \n__________________________________________________________________________________________________\nlanguage_encode (InputLayer)    [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_features_7 (DenseFeatures (None, 1)            0           engaged_with_user_follower_count[\n                                                                 language_encode[0][0]            \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 1)            2           dense_features_7[0][0]           \n==================================================================================================\nTotal params: 2\nTrainable params: 2\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df.compute(), test_size=0.2, random_state=777, shuffle=False)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=777, shuffle=False)\n",
    "\n",
    "batch_size = 128\n",
    "train_ds = df_to_tfdataset(train_df, 'is_like', batch_size=batch_size) # for like engagement\n",
    "# val_ds = df_to_tfdataset(val_df, 'is_like', batch_size=batch_size)\n",
    "test_ds = df_to_tfdataset(test_df, 'is_like', batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "## 4. Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({enaging_user_id: (None,), tweet_id: (None,), language: (None,), engaged_with_user_follower_count: (None,), is_reply: (None,), is_retweet: (None,), is_comment: (None,), positive_cnt: (None,), language_encode: (None,)}, (None,)), types: ({enaging_user_id: tf.string, tweet_id: tf.string, language: tf.string, engaged_with_user_follower_count: tf.int32, is_reply: tf.int32, is_retweet: tf.int32, is_comment: tf.int32, positive_cnt: tf.uint8, language_encode: tf.int64}, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "15167/15167 [==============================] - 25s 1ms/step - loss: 0.4387 - accuracy: 0.5611 - val_loss: 0.3975 - val_accuracy: 0.6025\n",
      "Epoch 2/10\n",
      "15167/15167 [==============================] - 23s 1ms/step - loss: 0.3989 - accuracy: 0.6011 - val_loss: 0.3975 - val_accuracy: 0.6025\n",
      "Epoch 3/10\n",
      "15167/15167 [==============================] - 22s 1ms/step - loss: 0.3980 - accuracy: 0.6020 - val_loss: 0.3975 - val_accuracy: 0.6025\n",
      "Epoch 4/10\n",
      "15167/15167 [==============================] - 21s 1ms/step - loss: 0.3984 - accuracy: 0.6015 - val_loss: 0.3975 - val_accuracy: 0.6025\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-95b0240228c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_ds,\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=10)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/dask-cudf/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "            validation_split=0.1,\n",
    "            batch_size=batch_size\n",
    "            epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "source": [
    "## 5. Predict engagements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_like = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_like = np.reshape(predict_like, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict_like'] = predict_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rce_like = compute_rce(test_df['predict_like'].to_array(), test_df['is_like'].to_array())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1931.390374453516"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "rce_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}