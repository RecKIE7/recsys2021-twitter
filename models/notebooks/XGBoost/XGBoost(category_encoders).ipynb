{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "dask-cudf",
   "display_name": "Python 3.7.10 64-bit ('dask-cudf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd, numpy as np, gc\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "from utils.util import *\n",
    "from utils.evaluate import calculate_ctr, compute_rce, average_precision_score\n",
    "from utils.dataiter import Dataiter\n",
    "from utils.preprocessing import *\n",
    "from utils.target_encode import MTE_one_shot\n",
    "\n",
    "import core.config as conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{conf.raw_lzo_path}/part-00000'\n",
    "train = read_data(path)\n",
    "path = f'{conf.raw_lzo_path}/part-00001'\n",
    "train2 = read_data(path)\n",
    "path = f'{conf.raw_lzo_path}/part-00002'\n",
    "valid = read_data(path)\n",
    "gc.collect()\n",
    "save_memory( train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MTE_one_shot:\n",
    "    \n",
    "    def __init__(self, folds, smooth, seed=42):\n",
    "        self.folds = folds\n",
    "        self.seed = seed\n",
    "        self.smooth = smooth\n",
    "        # self.agg_all = pd.DataFrame()\n",
    "        \n",
    "    def fit_transform(self, train, x_col, y_col, y_mean=None, out_col = None, out_dtype=None):\n",
    "        \n",
    "        self.y_col = y_col\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        if 'fold' not in train.columns:\n",
    "            fsize = len(train)//self.folds\n",
    "            train['fold'] = 1\n",
    "            train['fold'] = train['fold'].cumsum()\n",
    "            train['fold'] = train['fold']//fsize\n",
    "            train['fold'] = train['fold']%self.folds\n",
    "        \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'TE_{tag}_{self.y_col}'\n",
    "        \n",
    "        if y_mean is None:\n",
    "            y_mean = train[y_col].mean()#.compute().astype('float32')\n",
    "        self.mean = y_mean # mean도 누적해서 바꿔주면 좋을듯\n",
    "        \n",
    "        cols = ['fold',x_col] if isinstance(x_col,str) else ['fold']+x_col\n",
    "        \n",
    "        agg_each_fold = train.groupby(cols).agg({y_col:['count','sum']}).reset_index()\n",
    "        agg_each_fold.columns = cols + ['count_y','sum_y']\n",
    "        \n",
    "        agg_all = agg_each_fold.groupby(x_col).agg({'count_y':'sum','sum_y':'sum'}).reset_index()\n",
    "        cols = [x_col] if isinstance(x_col,str) else x_col\n",
    "        agg_all.columns = cols + ['count_y_all','sum_y_all']\n",
    "        \n",
    "        agg_each_fold = agg_each_fold.merge(agg_all,on=x_col,how='left')\n",
    "        agg_each_fold['count_y_all'] = agg_each_fold['count_y_all'] - agg_each_fold['count_y']\n",
    "        agg_each_fold['sum_y_all'] = agg_each_fold['sum_y_all'] - agg_each_fold['sum_y']\n",
    "        agg_each_fold[out_col] = (agg_each_fold['sum_y_all']+self.smooth*self.mean)/(agg_each_fold['count_y_all']+self.smooth)\n",
    "        agg_each_fold = agg_each_fold.drop(['count_y_all','count_y','sum_y_all','sum_y'],axis=1)\n",
    "        \n",
    "        agg_all[out_col] = (agg_all['sum_y_all']+self.smooth*self.mean)/(agg_all['count_y_all']+self.smooth)\n",
    "        agg_all = agg_all.drop(['count_y_all','sum_y_all'],axis=1)\n",
    "        \n",
    "        if hasattr(self, 'agg_all'):\n",
    "            print('train2')\n",
    "            self.agg_all = pd.concat([self.agg_all, agg_all])\n",
    "            \n",
    "        else:\n",
    "            print('train1')\n",
    "            self.agg_all = agg_all\n",
    "        \n",
    "        self.agg_all = self.agg_all.drop_duplicates(keep='last')\n",
    "        # agg_all.to_csv('agg_all.csv', index=False)\n",
    "\n",
    "        train.columns\n",
    "        cols = ['fold',x_col] if isinstance(x_col,str) else ['fold']+x_col\n",
    "        train = train.merge(agg_each_fold,on=cols,how='left')\n",
    "        del agg_each_fold\n",
    "        #self.agg_each_fold = agg_each_fold\n",
    "        #train[out_col] = train.map_partitions(lambda cudf_df: cudf_df[out_col].nans_to_nulls())\n",
    "        train[out_col] = train[out_col].fillna(self.mean)\n",
    "        \n",
    "        if out_dtype is not None:\n",
    "            train[out_col] = train[out_col].astype(out_dtype)\n",
    "        return train\n",
    "    \n",
    "    def transform(self, test, x_col, out_col = None, out_dtype=None):\n",
    "        \n",
    "        # self.agg_all = pd.read_csv('agg_all.csv')\n",
    "        print(len(self.agg_all))\n",
    "        \n",
    "        if out_col is None:\n",
    "            tag = x_col if isinstance(x_col,str) else '_'.join(x_col)\n",
    "            out_col = f'TE_{tag}_{self.y_col}'\n",
    "        test = test.merge(self.agg_all,on=x_col,how='left')\n",
    "        test[out_col] = test[out_col].fillna(self.mean)\n",
    "        # test[out_col] = test[out_col].fillna(0)\n",
    "        if out_dtype is not None:\n",
    "            test[out_col] = test[out_col].astype(out_dtype)\n",
    "        return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataframe_types(df, train):\n",
    "    df['id']   = np.arange( df.shape[0] )\n",
    "    df['id']   = df['id'].astype(np.uint32)\n",
    "\n",
    "    if train:\n",
    "        df['reply_timestamp']   = df['reply_timestamp'].fillna(0)\n",
    "        df['retweet_timestamp'] = df['retweet_timestamp'].fillna(0)\n",
    "        df['comment_timestamp'] = df['comment_timestamp'].fillna(0)\n",
    "        df['like_timestamp']    = df['like_timestamp'].fillna(0)\n",
    "\n",
    "        df['reply_timestamp']   = df['reply_timestamp'].astype(np.uint32)\n",
    "        df['retweet_timestamp'] = df['retweet_timestamp'].astype(np.uint32)\n",
    "        df['comment_timestamp'] = df['comment_timestamp'].astype(np.uint32)\n",
    "        df['like_timestamp']    = df['like_timestamp'].astype(np.uint32)\n",
    "\n",
    "    df['tweet_timestamp']         = df['tweet_timestamp'].astype( np.uint32 )\n",
    "    df['creator_follower_count']  = df['creator_follower_count'].astype( np.uint32 )\n",
    "    df['creator_following_count'] = df['creator_following_count'].astype( np.uint32 )\n",
    "    df['creator_account_creation']= df['creator_account_creation'].astype( np.uint32 )\n",
    "    df['engager_follower_count']  = df['engager_follower_count'].astype( np.uint32 )\n",
    "    df['engager_following_count'] = df['engager_following_count'].astype( np.uint32 )\n",
    "    df['engager_account_creation']= df['engager_account_creation'].astype( np.uint32 )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(df, target, train):\n",
    "    df = set_dataframe_types(df, train)\n",
    "    # df = df.set_index('id')\n",
    "    # df.columns = conf.raw_features + conf.labels\n",
    "    df = df.drop('text_tokens', axis=1)\n",
    "    \n",
    "    df = feature_extraction(df, features=conf.used_features, train=train) # extract 'used_features'\n",
    "    cols = []\n",
    "    print('target_encode')\n",
    "    for c in tqdm([\n",
    "        # ['engager_id'],\n",
    "        ['engager_id','tweet_type','language'],\n",
    "        # ['creator_id'],\n",
    "        # ['domains','media','tweet_type','language']\n",
    "        ]):\n",
    "        out_col = 'TE_'+'_'.join(c)+'_'+target\n",
    "        if os.path.exists('./encoder.pkl'):\n",
    "            with open('./encoder.pkl', 'rb') as f:\n",
    "                encoder = pickle.load(f)\n",
    "        else:\n",
    "            encoder = MTE_one_shot(folds=5,smooth=20)\n",
    "\n",
    "        if train:\n",
    "            \n",
    "            df = encoder.fit_transform(df, c, target, out_col=out_col, out_dtype='float32')\n",
    "            with open('encoder.pkl', 'wb') as f:\n",
    "                pickle.dump(encoder, f)\n",
    "        else:\n",
    "                df = encoder.transform(df, c, out_col=out_col, out_dtype='float32')\n",
    "        \n",
    "\n",
    "        cols.append(out_col)\n",
    "        del encoder\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]target_encode\n",
      "train1\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.38s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TARGET = 'like'\n",
    "train = preprocess(train, TARGET, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]target_encode\n",
      "train2\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.42s/it]\n"
     ]
    }
   ],
   "source": [
    "train2 = preprocess(train2, TARGET, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]target_encode\n",
      "5188745\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.69s/it]\n"
     ]
    }
   ],
   "source": [
    "valid = preprocess(valid, TARGET, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['reply', 'retweet', 'comment', 'like']\n",
    "DONT_USE = ['timestamp','creator_account_creation','engager_account_creation','engage_time',\n",
    "            'creator_account_creation', 'engager_account_creation',\n",
    "            'fold','tweet_id', \n",
    "            'tr','dt_day','','ypred',\n",
    "            'engager_id','creator_id','engager_is_verified',\n",
    "            'elapsed_time',\n",
    "            'links','domains','hashtags0','hashtags1',\n",
    "            'hashtags','tweet_hash','dt_second','id',\n",
    "            'tw_hash0',\n",
    "            'tw_hash1',\n",
    "            'tw_rt_uhash',\n",
    "            'same_language', 'nan_language','language',\n",
    "            'tw_hash', 'tw_freq_hash','tw_first_word', 'tw_second_word', 'tw_last_word', 'tw_llast_word',\n",
    "            'ypred','creator_count_combined','creator_user_fer_count_delta_time','creator_user_fing_count_delta_time','creator_user_fering_count_delta_time','creator_user_fing_count_mode','creator_user_fer_count_mode','creator_user_fering_count_mode'\n",
    "            'reply', 'retweet', 'comment', 'like', 'pred'\n",
    "            \n",
    "           ]\n",
    "DONT_USE += label_names\n",
    "DONT_USE += conf.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_parms = { \n",
    "                'max_depth':8, \n",
    "                'learning_rate':0.025, \n",
    "                'subsample':0.85,\n",
    "                'colsample_bytree':0.35, \n",
    "                'eval_metric':'logloss',\n",
    "                'objective':'binary:logistic',\n",
    "                'tree_method':'gpu_hist',\n",
    "                #'predictor': 'gpu_predictor',\n",
    "                'seed': 1,\n",
    "            }\n",
    "LR = [0.05,0.03,0.07,0.01]\n",
    "xgb_parms['learning_rate'] = LR[3]\n",
    "RMV = [c for c in DONT_USE if c in train.columns]\n",
    "dtrain = xgb.DMatrix(data=train.drop(RMV, axis=1) ,label=train[TARGET].values)\n",
    "model = xgb.train(xgb_parms, \n",
    "                        dtrain=dtrain,\n",
    "                        num_boost_round=500,\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['tweet_type', 'creator_follower_count', 'creator_following_count',\n",
       "       'media', 'tweet_timestamp', 'dt_dow', 'dt_hour', 'len_domains',\n",
       "       'TE_engager_id_tweet_type_language_like'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train.drop(RMV, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMV = [c for c in DONT_USE if c in valid.columns]\n",
    "dvalid = xgb.DMatrix(data=valid.drop(RMV, axis=1) )\n",
    "valid['pred'] = model.predict(dvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['creator_id', 'engager_id', 'tweet_id', 'tweet_type', 'language',\n",
       "       'creator_follower_count', 'creator_following_count', 'domains', 'media',\n",
       "       'tweet_timestamp', 'dt_day', 'dt_dow', 'dt_hour', 'len_domains',\n",
       "       'TE_engager_id_like', 'pred'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4a2d4df72be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./encoder.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0          0.615871\n",
       "1          0.615871\n",
       "2          0.498268\n",
       "3          0.363982\n",
       "4          0.429048\n",
       "             ...   \n",
       "5635399    0.409211\n",
       "5635400    0.272296\n",
       "5635401    0.439516\n",
       "5635402    0.296145\n",
       "5635403    0.296145\n",
       "Name: pred, Length: 5635404, dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "valid['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_all = pd.read_csv('agg_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               engager_id  tweet_type  language  \\\n",
       "0        0000030E0DCCFDF9DBF2DDC031E6DA58           1        19   \n",
       "1        0000055BD24EE1ED318EAC7970A78849           1        10   \n",
       "2        000005BCF00DCCEABCF7F82BDCFB3543           1        10   \n",
       "3        000013136E63BA1782731FA3E59F7A30           2        19   \n",
       "4        00001353EE2339E074323A06CCC5D89E           2        61   \n",
       "...                                   ...         ...       ...   \n",
       "2593956  FFFFE27E2E0BDCCDC5D8E1BF1A50E5B2           1        61   \n",
       "2593957  FFFFE6F4A73D42C558AB2BB375109AC5           2        46   \n",
       "2593958  FFFFE7D1852F5FC078F31004CDC344D6           2        48   \n",
       "2593959  FFFFED3C5DFF871BFE0C8FF745396A7D           1        61   \n",
       "2593960  FFFFF50BA9D4FF3225576C8996BE8BAC           1        19   \n",
       "\n",
       "         TE_engager_id_tweet_type_language_like  \n",
       "0                                      0.379077  \n",
       "1                                      0.379077  \n",
       "2                                      0.379077  \n",
       "3                                      0.426697  \n",
       "4                                      0.426697  \n",
       "...                                         ...  \n",
       "2593956                                0.379077  \n",
       "2593957                                0.426697  \n",
       "2593958                                0.426697  \n",
       "2593959                                0.379077  \n",
       "2593960                                0.426697  \n",
       "\n",
       "[2593961 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>engager_id</th>\n      <th>tweet_type</th>\n      <th>language</th>\n      <th>TE_engager_id_tweet_type_language_like</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000030E0DCCFDF9DBF2DDC031E6DA58</td>\n      <td>1</td>\n      <td>19</td>\n      <td>0.379077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000055BD24EE1ED318EAC7970A78849</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.379077</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000005BCF00DCCEABCF7F82BDCFB3543</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0.379077</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000013136E63BA1782731FA3E59F7A30</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0.426697</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00001353EE2339E074323A06CCC5D89E</td>\n      <td>2</td>\n      <td>61</td>\n      <td>0.426697</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2593956</th>\n      <td>FFFFE27E2E0BDCCDC5D8E1BF1A50E5B2</td>\n      <td>1</td>\n      <td>61</td>\n      <td>0.379077</td>\n    </tr>\n    <tr>\n      <th>2593957</th>\n      <td>FFFFE6F4A73D42C558AB2BB375109AC5</td>\n      <td>2</td>\n      <td>46</td>\n      <td>0.426697</td>\n    </tr>\n    <tr>\n      <th>2593958</th>\n      <td>FFFFE7D1852F5FC078F31004CDC344D6</td>\n      <td>2</td>\n      <td>48</td>\n      <td>0.426697</td>\n    </tr>\n    <tr>\n      <th>2593959</th>\n      <td>FFFFED3C5DFF871BFE0C8FF745396A7D</td>\n      <td>1</td>\n      <td>61</td>\n      <td>0.379077</td>\n    </tr>\n    <tr>\n      <th>2593960</th>\n      <td>FFFFF50BA9D4FF3225576C8996BE8BAC</td>\n      <td>1</td>\n      <td>19</td>\n      <td>0.426697</td>\n    </tr>\n  </tbody>\n</table>\n<p>2593961 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "agg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('agg_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "116381235657025742637517049115971"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "int('000005BCF00DCCEABCF7F82BDCFB3543', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}