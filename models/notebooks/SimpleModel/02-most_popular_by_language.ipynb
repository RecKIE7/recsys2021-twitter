{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "dask-cudf",
   "display_name": "dask-cudf",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Baseline - Extract most popular tweet for each langugage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.cuda_cluster import *\n",
    "from utils.dataset import read_data, factorize_small_cardinality\n",
    "from utils.evaluate import calculate_ctr, compute_rce, average_precision_score\n",
    "\n",
    "import core.config as conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42411' processes=1 threads=1, memory=33.47 GB>"
      ],
      "text/html": "<table style=\"border: 2px solid white;\">\n<tr>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Client</h3>\n<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n  <li><b>Scheduler: </b>tcp://127.0.0.1:42411</li>\n  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n</ul>\n</td>\n<td style=\"vertical-align: top; border: 0px solid white\">\n<h3 style=\"text-align: left;\">Cluster</h3>\n<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n  <li><b>Workers: </b>1</li>\n  <li><b>Cores: </b>1</li>\n  <li><b>Memory: </b>33.47 GB</li>\n</ul>\n</td>\n</tr>\n</table>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "source": [
    "## 1. Load data & preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of rows: 3033347\n"
     ]
    }
   ],
   "source": [
    "# data_path = conf.raw_data_path + '*' # for all dataset\n",
    "data_path = conf.raw_data_path + 'part-00175'\n",
    "ori_df = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ori_df[['enaging_user_id', 'tweet_timestamp', 'language', 'tweet_id', 'reply_timestamp', 'retweet_timestamp','retweet_with_comment_timestamp', 'like_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_reply'] = df['reply_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_retweet'] = df['retweet_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_comment'] = df['retweet_with_comment_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "df['is_like'] = df['like_timestamp'].compute().applymap(lambda x: 1 if x > 0 else 0).astype(np.int32)\n",
    "\n",
    "df['positive_cnt'] = df[['is_like', 'is_retweet', 'is_reply', 'is_comment']].sum(axis=1).astype(np.uint8)\n",
    "\n",
    "df = df.drop('reply_timestamp', axis=1)\n",
    "df = df.drop('retweet_timestamp', axis=1)\n",
    "df = df.drop('retweet_with_comment_timestamp', axis=1)\n",
    "df = df.drop('like_timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, idx_to_tweet = factorize_small_cardinality(df, 'tweet_id')\n",
    "df, idx_to_language = factorize_small_cardinality(df, 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     enaging_user_id  tweet_timestamp  \\\n",
       "id                                                      \n",
       "1   411C3FA9B6AB5CA95192D875CDC22823       1612993854   \n",
       "2   E764026AB0E38A5C2FF19921D73B6C18       1612886900   \n",
       "3   455134BAAD3EAC4093393EC233FBAEF9       1614019237   \n",
       "4   92D70497B86CAFBA5C51E331084462AD       1612779567   \n",
       "5   DC1C8A9412B9E266A4C3D4CAF6DB06CB       1613822114   \n",
       "\n",
       "                            language                          tweet_id  \\\n",
       "id                                                                       \n",
       "1   B8B04128918BBF54E2E178BFF1ABA833  C8F345CF8BC7A86E34572072ECFBBEC4   \n",
       "2   9FCF19233EAD65EA6E32C2E6DC03A444  C1E31636C343B780BA776E4B73147028   \n",
       "3   B0FA488F2911701DD8EC5B1EA5E322D8  B436C84E80C2430BA9DE41FDF04C73BF   \n",
       "4   1F73BB863A39DB62B4A55B7E558DB1E8  033FFA42C8AD502057AE96C8B4B812BE   \n",
       "5   E7F038DE3EAD397AEC9193686C911677  84F2E902BA3CF3B34B8D056F6F78D488   \n",
       "\n",
       "    is_reply  is_retweet  is_comment  is_like  positive_cnt  tweet_id_encode  \\\n",
       "id                                                                             \n",
       "1          0           0           0        1             1          2214622   \n",
       "2          0           0           0        0             0          2136815   \n",
       "3          1           0           0        0             1          1986297   \n",
       "4          0           0           0        1             1            35685   \n",
       "5          0           0           0        0             0          1465500   \n",
       "\n",
       "    language_encode  \n",
       "id                   \n",
       "1                48  \n",
       "2                43  \n",
       "3                46  \n",
       "4                 5  \n",
       "5                61  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enaging_user_id</th>\n      <th>tweet_timestamp</th>\n      <th>language</th>\n      <th>tweet_id</th>\n      <th>is_reply</th>\n      <th>is_retweet</th>\n      <th>is_comment</th>\n      <th>is_like</th>\n      <th>positive_cnt</th>\n      <th>tweet_id_encode</th>\n      <th>language_encode</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>411C3FA9B6AB5CA95192D875CDC22823</td>\n      <td>1612993854</td>\n      <td>B8B04128918BBF54E2E178BFF1ABA833</td>\n      <td>C8F345CF8BC7A86E34572072ECFBBEC4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2214622</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E764026AB0E38A5C2FF19921D73B6C18</td>\n      <td>1612886900</td>\n      <td>9FCF19233EAD65EA6E32C2E6DC03A444</td>\n      <td>C1E31636C343B780BA776E4B73147028</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2136815</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>455134BAAD3EAC4093393EC233FBAEF9</td>\n      <td>1614019237</td>\n      <td>B0FA488F2911701DD8EC5B1EA5E322D8</td>\n      <td>B436C84E80C2430BA9DE41FDF04C73BF</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1986297</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92D70497B86CAFBA5C51E331084462AD</td>\n      <td>1612779567</td>\n      <td>1F73BB863A39DB62B4A55B7E558DB1E8</td>\n      <td>033FFA42C8AD502057AE96C8B4B812BE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35685</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DC1C8A9412B9E266A4C3D4CAF6DB06CB</td>\n      <td>1613822114</td>\n      <td>E7F038DE3EAD397AEC9193686C911677</td>\n      <td>84F2E902BA3CF3B34B8D056F6F78D488</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1465500</td>\n      <td>61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "### train, valid data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df.compute(), test_size=0.5, random_state=777, shuffle=False)"
   ]
  },
  {
   "source": [
    "### Group by language"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagements = train_df.groupby(['language_encode', 'tweet_id_encode'])[['is_reply',\t'is_retweet',\t'is_comment',\t'is_like',\t'positive_cnt']].sum()\n",
    "engagements = engagements.reset_index()\n",
    "engagements = engagements.set_index('language_encode', drop=True)\n",
    "\n",
    "# engagements.loc[23].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 74%|███████▍  | 49/66 [00:00<00:00, 87.91it/s]There is no data on language  26\n",
      "There is no data on language  34\n",
      "There is no data on language  38\n",
      "100%|██████████| 66/66 [00:00<00:00, 95.39it/s]\n"
     ]
    }
   ],
   "source": [
    "n_languages = 66\n",
    "language_engagements = [[] for _ in range(n_languages)]\n",
    "\n",
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        tmp = engagements.loc[i]\n",
    "        tmp = tmp.sort_values('positive_cnt', ascending=False).reset_index()\n",
    "        language_engagements[i] = tmp\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# the largest value among positive engagements for each language\n",
      "language 0 :  5\n",
      "language 1 :  1\n",
      "language 2 :  3\n",
      "language 3 :  4\n",
      "language 4 :  4\n",
      "language 5 :  15\n",
      "language 6 :  6\n",
      "language 7 :  5\n",
      "language 8 :  14\n",
      "language 9 :  7\n",
      "language 10 :  53\n",
      "language 11 :  4\n",
      "language 12 :  2\n",
      "language 13 :  2\n",
      "language 14 :  2\n",
      "language 15 :  3\n",
      "language 16 :  4\n",
      "language 17 :  2\n",
      "language 18 :  3\n",
      "language 19 :  47\n",
      "language 20 :  3\n",
      "language 21 :  5\n",
      "language 22 :  4\n",
      "language 23 :  4\n",
      "language 24 :  2\n",
      "language 25 :  3\n",
      "There is no data on language  26\n",
      "language 27 :  2\n",
      "language 28 :  3\n",
      "language 29 :  5\n",
      "language 30 :  1\n",
      "language 31 :  5\n",
      "language 32 :  6\n",
      "language 33 :  8\n",
      "There is no data on language  34\n",
      "language 35 :  4\n",
      "language 36 :  54\n",
      "language 37 :  3\n",
      "There is no data on language  38\n",
      "language 39 :  2\n",
      "language 40 :  11\n",
      "language 41 :  6\n",
      "language 42 :  1\n",
      "language 43 :  11\n",
      "language 44 :  2\n",
      "language 45 :  15\n",
      "language 46 :  12\n",
      "language 47 :  9\n",
      "language 48 :  17\n",
      "language 49 :  3\n",
      "language 50 :  2\n",
      "language 51 :  5\n",
      "language 52 :  2\n",
      "language 53 :  1\n",
      "language 54 :  4\n",
      "language 55 :  10\n",
      "language 56 :  7\n",
      "language 57 :  6\n",
      "language 58 :  2\n",
      "language 59 :  6\n",
      "language 60 :  6\n",
      "language 61 :  16\n",
      "language 62 :  27\n",
      "language 63 :  2\n",
      "language 64 :  4\n",
      "language 65 :  2\n"
     ]
    }
   ],
   "source": [
    "print('# the largest value among positive engagements for each language')\n",
    "\n",
    "for i in range(n_languages):\n",
    "    try:\n",
    "        print(f'language {i} : ', language_engagements[i].loc[0]['positive_cnt'])\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# the number of rows for each language\nlanguage 0\n - all rows :  4116 ,  positive rows :  2227\nlanguage 1\n - all rows :  26 ,  positive rows :  14\nlanguage 2\n - all rows :  502 ,  positive rows :  344\nlanguage 3\n - all rows :  639 ,  positive rows :  348\nlanguage 4\n - all rows :  1635 ,  positive rows :  866\nlanguage 5\n - all rows :  63395 ,  positive rows :  35008\nlanguage 6\n - all rows :  3534 ,  positive rows :  1644\nlanguage 7\n - all rows :  8762 ,  positive rows :  4483\nlanguage 8\n - all rows :  10224 ,  positive rows :  5483\nlanguage 9\n - all rows :  13310 ,  positive rows :  7369\nlanguage 10\n - all rows :  93032 ,  positive rows :  46947\nlanguage 11\n - all rows :  835 ,  positive rows :  445\nlanguage 12\n - all rows :  45 ,  positive rows :  27\nlanguage 13\n - all rows :  309 ,  positive rows :  156\nlanguage 14\n - all rows :  378 ,  positive rows :  189\nlanguage 15\n - all rows :  70 ,  positive rows :  40\nlanguage 16\n - all rows :  744 ,  positive rows :  353\nlanguage 17\n - all rows :  293 ,  positive rows :  186\nlanguage 18\n - all rows :  713 ,  positive rows :  349\nlanguage 19\n - all rows :  514320 ,  positive rows :  248447\nlanguage 20\n - all rows :  1366 ,  positive rows :  774\nlanguage 21\n - all rows :  837 ,  positive rows :  441\nlanguage 22\n - all rows :  387 ,  positive rows :  198\nlanguage 23\n - all rows :  12235 ,  positive rows :  6417\nlanguage 24\n - all rows :  123 ,  positive rows :  81\nlanguage 25\n - all rows :  9793 ,  positive rows :  5559\nlanguage 26\nThere is no data on language  26\nlanguage 27\n - all rows :  586 ,  positive rows :  427\nlanguage 28\n - all rows :  283 ,  positive rows :  164\nlanguage 29\n - all rows :  1412 ,  positive rows :  746\nlanguage 30\n - all rows :  20 ,  positive rows :  10\nlanguage 31\n - all rows :  3763 ,  positive rows :  1893\nlanguage 32\n - all rows :  231 ,  positive rows :  111\nlanguage 33\n - all rows :  24999 ,  positive rows :  12377\nlanguage 34\nThere is no data on language  34\nlanguage 35\n - all rows :  2283 ,  positive rows :  1285\nlanguage 36\n - all rows :  33489 ,  positive rows :  16309\nlanguage 37\n - all rows :  600 ,  positive rows :  275\nlanguage 38\nThere is no data on language  38\nlanguage 39\n - all rows :  157 ,  positive rows :  71\nlanguage 40\n - all rows :  2233 ,  positive rows :  1149\nlanguage 41\n - all rows :  37559 ,  positive rows :  19782\nlanguage 42\n - all rows :  16 ,  positive rows :  11\nlanguage 43\n - all rows :  45415 ,  positive rows :  25304\nlanguage 44\n - all rows :  225 ,  positive rows :  125\nlanguage 45\n - all rows :  3113 ,  positive rows :  1668\nlanguage 46\n - all rows :  123410 ,  positive rows :  60696\nlanguage 47\n - all rows :  16854 ,  positive rows :  9422\nlanguage 48\n - all rows :  114392 ,  positive rows :  58758\nlanguage 49\n - all rows :  1203 ,  positive rows :  613\nlanguage 50\n - all rows :  433 ,  positive rows :  247\nlanguage 51\n - all rows :  693 ,  positive rows :  379\nlanguage 52\n - all rows :  220 ,  positive rows :  148\nlanguage 53\n - all rows :  19 ,  positive rows :  15\nlanguage 54\n - all rows :  418 ,  positive rows :  231\nlanguage 55\n - all rows :  790 ,  positive rows :  484\nlanguage 56\n - all rows :  1752 ,  positive rows :  909\nlanguage 57\n - all rows :  5069 ,  positive rows :  2589\nlanguage 58\n - all rows :  75 ,  positive rows :  48\nlanguage 59\n - all rows :  486 ,  positive rows :  263\nlanguage 60\n - all rows :  28358 ,  positive rows :  14185\nlanguage 61\n - all rows :  253767 ,  positive rows :  123879\nlanguage 62\n - all rows :  1309 ,  positive rows :  666\nlanguage 63\n - all rows :  95 ,  positive rows :  60\nlanguage 64\n - all rows :  660 ,  positive rows :  317\nlanguage 65\n - all rows :  122 ,  positive rows :  74\n"
     ]
    }
   ],
   "source": [
    "print('# the number of rows for each language')\n",
    "\n",
    "for i in range(n_languages):\n",
    "    try:\n",
    "        print(f'language {i}')\n",
    "        print(' - all rows : ', len(language_engagements[i]),  ',  positive rows : ', len(language_engagements[i].loc[language_engagements[i]['positive_cnt'] != 0]))\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## 2. Get the popular tweets for each language"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = 1000\n",
    "recommend_list_like = [[] for _ in range(n_languages)]\n",
    "recommend_list_reply = [[] for _ in range(n_languages)]\n",
    "recommend_list_comment = [[] for _ in range(n_languages)]\n",
    "recommend_list_retweet = [[] for _ in range(n_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 55%|█████▍    | 36/66 [00:00<00:00, 86.54it/s]There is no data on language  26\n",
      "There is no data on language  34\n",
      "There is no data on language  38\n",
      "100%|██████████| 66/66 [00:00<00:00, 81.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        recommend_list_like[i] = language_engagements[i].sort_values('is_like', ascending=False)[:topn-1]['tweet_id_encode'].to_array()\n",
    "        recommend_list_reply[i] = language_engagements[i].sort_values('is_reply', ascending=False)[:topn-1]['tweet_id_encode'].to_array()\n",
    "        recommend_list_comment[i] = language_engagements[i].sort_values('is_comment', ascending=False)[:topn-1]['tweet_id_encode'].to_array()\n",
    "        recommend_list_retweet[i] = language_engagements[i].sort_values('is_retweet', ascending=False)[:topn-1]['tweet_id_encode'].to_array()\n",
    "        \n",
    "    except:\n",
    "        print('There is no data on language ', str(i))"
   ]
  },
  {
   "source": [
    "## 3. Get user's language"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = val_df[['enaging_user_id', 'tweet_id_encode', 'language_encode', 'is_like', 'is_reply', 'is_comment', 'is_retweet']]"
   ]
  },
  {
   "source": [
    "## 4.  Predict engagements for each user\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1) Like"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 66/66 [00:01<00:00, 54.53it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_df['predict_like'] = 0\n",
    "\n",
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        tmp = predict_df[predict_df['language_encode'] == i]\n",
    "        positive = tmp[tmp['tweet_id_encode'].isin(recommend_list_like[i]) == True]        \n",
    "        indexes = positive.index.to_array()\n",
    "        predict_df.loc[indexes, 'predict_like'] = 1\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n"
   ]
  },
  {
   "source": [
    "### 2) Reply"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 66/66 [00:01<00:00, 53.75it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_df['predict_reply'] = 0\n",
    "\n",
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        tmp = predict_df[predict_df['language_encode'] == i]\n",
    "        positive = tmp[tmp['tweet_id_encode'].isin(recommend_list_reply[i]) == True]        \n",
    "        indexes = positive.index.to_array()\n",
    "        predict_df.loc[indexes, 'predict_reply'] = 1\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n"
   ]
  },
  {
   "source": [
    "### 3) Comment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 66/66 [00:01<00:00, 53.25it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_df['predict_comment'] = 0\n",
    "\n",
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        tmp = predict_df[predict_df['language_encode'] == i]\n",
    "        positive = tmp[tmp['tweet_id_encode'].isin(recommend_list_comment[i]) == True]        \n",
    "        indexes = positive.index.to_array()\n",
    "        predict_df.loc[indexes, 'predict_comment'] = 1\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n"
   ]
  },
  {
   "source": [
    "### 4) Retweet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 66/66 [00:01<00:00, 52.93it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_df['predict_retweet'] = 0\n",
    "\n",
    "for i in tqdm(range(n_languages)):\n",
    "    try:\n",
    "        tmp = predict_df[predict_df['language_encode'] == i]\n",
    "        positive = tmp[tmp['tweet_id_encode'].isin(recommend_list_retweet[i]) == True]        \n",
    "        indexes = positive.index.to_array()\n",
    "        predict_df.loc[indexes, 'predict_retweet'] = 1\n",
    "    except:\n",
    "        print('There is no data on language ', str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          enaging_user_id  tweet_id_encode  language_encode  \\\n",
       "2431037  8C01B8883F6B44F1C492AA9B0D433FBD          1227935                0   \n",
       "\n",
       "         is_like  is_reply  is_comment  is_retweet  predict_like  \\\n",
       "2431037        0         0           0           1             1   \n",
       "\n",
       "         predict_reply  predict_comment  predict_retweet  \n",
       "2431037              1                1                1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enaging_user_id</th>\n      <th>tweet_id_encode</th>\n      <th>language_encode</th>\n      <th>is_like</th>\n      <th>is_reply</th>\n      <th>is_comment</th>\n      <th>is_retweet</th>\n      <th>predict_like</th>\n      <th>predict_reply</th>\n      <th>predict_comment</th>\n      <th>predict_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2431037</th>\n      <td>8C01B8883F6B44F1C492AA9B0D433FBD</td>\n      <td>1227935</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "predict_df.loc[2431037]"
   ]
  },
  {
   "source": [
    "## 5. Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1923.629817245273 -775.0775126143292 -973.8460577441801 -977.3809442582101\n"
     ]
    }
   ],
   "source": [
    "rce_like = compute_rce(predict_df['predict_like'].to_array(), predict_df['is_like'].to_array())\n",
    "rce_reply = compute_rce(predict_df['predict_reply'].to_array(), predict_df['is_reply'].to_array())\n",
    "rce_comment = compute_rce(predict_df['predict_comment'].to_array(), predict_df['is_comment'].to_array())\n",
    "rce_rewteet = compute_rce(predict_df['predict_retweet'].to_array(), predict_df['is_retweet'].to_array())\n",
    "print(rce_like, rce_reply, rce_comment, rce_rewteet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.01823127326780151 0.004463772316680876 0.006216952844698359 0.008158198645698103\n"
     ]
    }
   ],
   "source": [
    "ap_like = average_precision_score(predict_df['predict_like'].to_array(), predict_df['is_like'].to_array())\n",
    "ap_reply = average_precision_score(predict_df['predict_reply'].to_array(), predict_df['is_reply'].to_array())\n",
    "ap_comment = average_precision_score(predict_df['predict_comment'].to_array(), predict_df['is_comment'].to_array())\n",
    "ap_retweet = average_precision_score(predict_df['predict_retweet'].to_array(), predict_df['is_retweet'].to_array())\n",
    "print(ap_like, ap_reply, ap_comment, ap_retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}