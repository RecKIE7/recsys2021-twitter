{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd, numpy as np, gc\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "from core import config as conf\n",
    "from utils.dataiter import Dataiter\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import save_model,load_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from utils.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils.dataiter import Dataset\n",
    "from utils.preprocessing import *\n",
    "from models.baseline.random_model import random_prediction_model\n",
    "from models.model.Ensemble_FFNN_ALL import Ensemble_FFNN_ALL\n",
    "# from models.model.XGBoost import XGBoost\n",
    "from core.config import raw_features\n",
    "import core.config as conf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('valid_prep.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/hdd/models/ensemble_ffnn_pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_features_to_idx = dict(zip(raw_features, range(len(raw_features))))\n",
    "float_formatter = \"{:.15f}\".format\n",
    "\n",
    "def parse_input_line(line):\n",
    "    features = line.split(\"\\x01\")\n",
    "    tweet_id = features[all_features_to_idx['tweet_id']]\n",
    "    user_id = features[all_features_to_idx['engager_id']]\n",
    "    input_feats = features[all_features_to_idx['text_tokens']]\n",
    "    return tweet_id, user_id, input_feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyez/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ predict ensemble model 0 ------\n",
      "------ predict ensemble model 1 ------\n",
      "------ predict ensemble model 2 ------\n",
      "------ predict ensemble model 3 ------\n",
      "------ predict ensemble model 4 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyez/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ predict ensemble model 0 ------\n",
      "------ predict ensemble model 1 ------\n",
      "------ predict ensemble model 2 ------\n",
      "------ predict ensemble model 3 ------\n",
      "------ predict ensemble model 4 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyez/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ predict ensemble model 0 ------\n",
      "------ predict ensemble model 1 ------\n",
      "------ predict ensemble model 2 ------\n",
      "------ predict ensemble model 3 ------\n",
      "------ predict ensemble model 4 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyez/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ predict ensemble model 0 ------\n",
      "------ predict ensemble model 1 ------\n",
      "------ predict ensemble model 2 ------\n",
      "------ predict ensemble model 3 ------\n",
      "------ predict ensemble model 4 ------\n"
     ]
    }
   ],
   "source": [
    "file = '/dataset/final_data/dataset/valid/part-0'\n",
    "# with open('results.csv', 'w') as output:\n",
    "\n",
    "pred_reply = Ensemble_FFNN_ALL(df, conf.REPLY).predict(model_path, model_num=2)\n",
    "pred_retweet = Ensemble_FFNN_ALL(df, conf.RETWEET).predict(model_path, model_num=2) \n",
    "pred_comment = Ensemble_FFNN_ALL(df, conf.COMMNET).predict(model_path, model_num=2) \n",
    "pred_like = Ensemble_FFNN_ALL(df, conf.LIKE).predict(model_path, model_num=2) \n",
    "\n",
    "#     with open(file, 'r') as f:\n",
    "#         for i, line in enumerate(f.readlines()):\n",
    "#             tweet_id, user_id, features = parse_input_line(line)\n",
    "#             '''\n",
    "#             ## XGBoost\n",
    "#             reply_pred = pred_reply[i]\n",
    "#             retweet_pred = pred_retweet[i]\n",
    "#             quote_pred = pred_comment[i]\n",
    "#             fav_pred = pred_like[i]\n",
    "#             '''\n",
    "#             reply_pred = pred_reply[i][0]\n",
    "#             retweet_pred = pred_retweet[i][0]\n",
    "#             quote_pred = pred_comment[i][0]\n",
    "#             fav_pred = pred_like[i][0]\n",
    "\n",
    "#             output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'w') as output:\n",
    "\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            tweet_id, user_id, features = parse_input_line(line)\n",
    "            '''\n",
    "            ## XGBoost\n",
    "            reply_pred = pred_reply[i]\n",
    "            retweet_pred = pred_retweet[i]\n",
    "            quote_pred = pred_comment[i]\n",
    "            fav_pred = pred_like[i]\n",
    "            '''\n",
    "            reply_pred = pred_reply[i][0]\n",
    "            retweet_pred = pred_retweet[i][0]\n",
    "            quote_pred = pred_comment[i][0]\n",
    "            fav_pred = pred_like[i][0]\n",
    "\n",
    "            output.write(f'{tweet_id},{user_id},{reply_pred},{retweet_pred},{quote_pred},{fav_pred}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-24 07:10:49.716984: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-06-24 07:10:49.717003: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "***************rce***************\n",
      "reply: 44.609677306317806\n",
      "like: 49.15610801670935\n",
      "comment: 49.6275797429087\n",
      "retweet: 38.02954387413343\n",
      "\n",
      "***************ap***************\n",
      "reply: 0.362111371277117\n",
      "like: 0.815626218131237\n",
      "comment: 0.22068255106073445\n",
      "retweet: 0.5686484342763285\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
